{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect Notebook to Google Drive\n"
      ],
      "metadata": {
        "id": "ZmRrNGr7cfUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUnoRVJ8ZENI",
        "outputId": "52ce4c50-64bd-4485-d6ff-1a1c0147f4a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "TwJ-5q_hZxT7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "root_path = \"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU1cwyb1ZyNg",
        "outputId": "9df2db7c-e408-48b3-df0d-741c68beb89c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install/Import packages "
      ],
      "metadata": {
        "id": "ltPkZVnZz_1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Hm3bBtKFhXiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94a9832-b712-4f48-d752-d01dd77648ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datasets"
      ],
      "metadata": {
        "id": "s8NJEHcnhR8t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read in Dataset"
      ],
      "metadata": {
        "id": "aciHHoXC0spR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = pd.read_csv(\"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien/data/raw/okcupid_profiles.csv\")\n",
        "df_raw.head(5)\n",
        "df = df_raw[[\"sex\", \"essay0\"]]"
      ],
      "metadata": {
        "id": "O7VxYnXHhkhT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.shape #59946, 31)\n",
        "#df.groupby([\"sex\"]).size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMYbZkIyo7nr",
        "outputId": "27b9d9cb-f96c-426c-fefa-883c5c4e5ef2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59946, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.head(2)"
      ],
      "metadata": {
        "id": "EkiVzZJ90nx4",
        "outputId": "de2f5cbf-fa1a-4582-dbea-16c680952ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  status sex orientation       body_type               diet    drinks  \\\n",
              "0   22  single   m    straight  a little extra  strictly anything  socially   \n",
              "1   35  single   m    straight         average       mostly other     often   \n",
              "\n",
              "       drugs                      education     ethnicity  ...  \\\n",
              "0      never  working on college/university  asian, white  ...   \n",
              "1  sometimes          working on space camp         white  ...   \n",
              "\n",
              "                                              essay0  \\\n",
              "0  about me:  i would love to think that i was so...   \n",
              "1  i am a chef: this is what that means. 1. i am ...   \n",
              "\n",
              "                                              essay1  \\\n",
              "0  currently working as an international agent fo...   \n",
              "1  dedicating everyday to being an unbelievable b...   \n",
              "\n",
              "                                              essay2  \\\n",
              "0  making people laugh. ranting about a good salt...   \n",
              "1  being silly. having ridiculous amonts of fun w...   \n",
              "\n",
              "                                              essay3  \\\n",
              "0  the way i look. i am a six foot half asian, ha...   \n",
              "1                                                NaN   \n",
              "\n",
              "                                              essay4  \\\n",
              "0  books: absurdistan, the republic, of mice and ...   \n",
              "1  i am die hard christopher moore fan. i don't r...   \n",
              "\n",
              "                                              essay5  \\\n",
              "0                  food. water. cell phone. shelter.   \n",
              "1  delicious porkness in all of its glories. my b...   \n",
              "\n",
              "                        essay6  \\\n",
              "0  duality and humorous things   \n",
              "1                          NaN   \n",
              "\n",
              "                                              essay7  \\\n",
              "0  trying to find someone to hang out with. i am ...   \n",
              "1                                                NaN   \n",
              "\n",
              "                                              essay8  \\\n",
              "0  i am new to california and looking for someone...   \n",
              "1  i am very open and will share just about anyth...   \n",
              "\n",
              "                                              essay9  \n",
              "0  you want to be swept off your feet! you are ti...  \n",
              "1                                                NaN  \n",
              "\n",
              "[2 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1523b1db-cc4d-4120-a394-9bd6e71ed144\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>status</th>\n",
              "      <th>sex</th>\n",
              "      <th>orientation</th>\n",
              "      <th>body_type</th>\n",
              "      <th>diet</th>\n",
              "      <th>drinks</th>\n",
              "      <th>drugs</th>\n",
              "      <th>education</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>...</th>\n",
              "      <th>essay0</th>\n",
              "      <th>essay1</th>\n",
              "      <th>essay2</th>\n",
              "      <th>essay3</th>\n",
              "      <th>essay4</th>\n",
              "      <th>essay5</th>\n",
              "      <th>essay6</th>\n",
              "      <th>essay7</th>\n",
              "      <th>essay8</th>\n",
              "      <th>essay9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>single</td>\n",
              "      <td>m</td>\n",
              "      <td>straight</td>\n",
              "      <td>a little extra</td>\n",
              "      <td>strictly anything</td>\n",
              "      <td>socially</td>\n",
              "      <td>never</td>\n",
              "      <td>working on college/university</td>\n",
              "      <td>asian, white</td>\n",
              "      <td>...</td>\n",
              "      <td>about me:  i would love to think that i was so...</td>\n",
              "      <td>currently working as an international agent fo...</td>\n",
              "      <td>making people laugh. ranting about a good salt...</td>\n",
              "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
              "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
              "      <td>food. water. cell phone. shelter.</td>\n",
              "      <td>duality and humorous things</td>\n",
              "      <td>trying to find someone to hang out with. i am ...</td>\n",
              "      <td>i am new to california and looking for someone...</td>\n",
              "      <td>you want to be swept off your feet! you are ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>single</td>\n",
              "      <td>m</td>\n",
              "      <td>straight</td>\n",
              "      <td>average</td>\n",
              "      <td>mostly other</td>\n",
              "      <td>often</td>\n",
              "      <td>sometimes</td>\n",
              "      <td>working on space camp</td>\n",
              "      <td>white</td>\n",
              "      <td>...</td>\n",
              "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
              "      <td>dedicating everyday to being an unbelievable b...</td>\n",
              "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
              "      <td>delicious porkness in all of its glories. my b...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i am very open and will share just about anyth...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1523b1db-cc4d-4120-a394-9bd6e71ed144')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1523b1db-cc4d-4120-a394-9bd6e71ed144 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1523b1db-cc4d-4120-a394-9bd6e71ed144');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction: Get Word Embedding Vector with BERT "
      ],
      "metadata": {
        "id": "rDqercXygil-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial: https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
        "\n",
        "https://huggingface.co/docs/transformers/tasks/sequence_classification"
      ],
      "metadata": {
        "id": "awJuCPYwoX7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT input Variables: \n",
        "* input_ids: id representation of each token (When decoded: \"[CLS] text [SEP] [PAD]...\"\n",
        "* token_typ_ids: Binary mask that identifies in which sequence a token belongs, for a single sequence all token type ids are 0\n",
        "* attention_mask: Binary mask that identifies whether a token is a real word or just padding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0ERI0iOCpaU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ],
      "metadata": {
        "id": "qMQjPcdN1Glr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets\n",
        "from datasets import load_dataset\n",
        "imdb = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "Agwa-5Wi1I2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter out NAs of essay0 (about me in profile text)\n",
        "df = df.dropna(subset =  [\"essay0\"])\n",
        "len(df[\"essay0\"]) #54458, before: 59946"
      ],
      "metadata": {
        "id": "hOJfdP6LrsmB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "zan7XRAX3gCP",
        "outputId": "c7d0d84a-5870-457b-94c3-7ac09eb48fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sex                                             essay0  female  label\n",
              "0   m  about me:  i would love to think that i was so...       0      0\n",
              "1   m  i am a chef: this is what that means. 1. i am ...       0      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-354bec17-896a-47d2-9805-4f573b613d1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>essay0</th>\n",
              "      <th>female</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m</td>\n",
              "      <td>about me:  i would love to think that i was so...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m</td>\n",
              "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-354bec17-896a-47d2-9805-4f573b613d1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-354bec17-896a-47d2-9805-4f573b613d1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-354bec17-896a-47d2-9805-4f573b613d1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make sex a binary variable \n",
        "df['female'] = np.where(df['sex']== 'f', 1, 0) #female = 1, male = 0"
      ],
      "metadata": {
        "id": "NahM-ll53nZA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split in train and test data\n",
        "training_data = df.sample(frac=0.8, random_state=25)\n",
        "testing_data = df.drop(training_data.index)"
      ],
      "metadata": {
        "id": "W0YkdWEr5afJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({\n",
        "     \"label\" : training_data[\"female\"],\n",
        "     \"text\" : training_data[\"essay0\"]\n",
        "})"
      ],
      "metadata": {
        "id": "VqIVKyeh5Afh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame({\n",
        "     \"label\" : testing_data[\"female\"],\n",
        "     \"text\" : testing_data[\"essay0\"]\n",
        "})"
      ],
      "metadata": {
        "id": "7WqODWTa5Plq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(2)"
      ],
      "metadata": {
        "id": "MkqFWfpZ5-Fc",
        "outputId": "406c83ca-8459-4a7f-a397-1832c44a57e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                               text\n",
              "25      0  hey to all, hope all is well and your having a...\n",
              "27      0  i suck at these things, but here it goes. i'm ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f38d9eb1-499e-4a73-8c15-15267fdb645e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>hey to all, hope all is well and your having a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>i suck at these things, but here it goes. i'm ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f38d9eb1-499e-4a73-8c15-15267fdb645e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f38d9eb1-499e-4a73-8c15-15267fdb645e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f38d9eb1-499e-4a73-8c15-15267fdb645e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(2)"
      ],
      "metadata": {
        "id": "TenfVOrS5JhG",
        "outputId": "710ca4ad-edcf-4e2d-ee30-611567d233f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text\n",
              "51487      1  hey hey what's goin on everyone? i'm 22 and li...\n",
              "18         0  some of my favorite things: riding my motorcyc..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28dbbd57-bc89-4e18-a81b-9dff8027493a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51487</th>\n",
              "      <td>1</td>\n",
              "      <td>hey hey what's goin on everyone? i'm 22 and li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>some of my favorite things: riding my motorcyc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28dbbd57-bc89-4e18-a81b-9dff8027493a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28dbbd57-bc89-4e18-a81b-9dff8027493a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28dbbd57-bc89-4e18-a81b-9dff8027493a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We need this dataset structure\n",
        "imdb"
      ],
      "metadata": {
        "id": "hQt560jc2Vv0",
        "outputId": "08e0e7e8-d801-47da-94f7-29e71415e5e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "cIVvF3Lf6PGg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_dict(train_df)\n",
        "test_dataset = Dataset.from_dict(test_df)\n",
        "my_dataset_dict = datasets.DatasetDict({\"train\":train_dataset,\"test\":test_dataset})"
      ],
      "metadata": {
        "id": "1ZUtpl3P3JDV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataset_dict"
      ],
      "metadata": {
        "id": "o95bAHYS6jGf",
        "outputId": "1a5af2ab-2216-4567-f594-43c3567dc034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 43566\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'text'],\n",
              "        num_rows: 10892\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "#Dictionary that maps the category in the dataframe into the id representation of our label \n",
        "labels = {\"f\": 0,          \n",
        "          \"m\": 1}"
      ],
      "metadata": {
        "id": "fYHSmG_Ho2t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"essay0\"] = df[\"essay0\"].to_string(index = False)\n",
        "\n",
        "#print(tokenizer(text, padding = \"max_length\", max_length = 512, truncation = True, return_tensors = \"pt\"))"
      ],
      "metadata": {
        "id": "LYyHo6noWELG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['female'] = np.where(df['sex'] == \"f\", 1, 0)\n",
        "#print(df[\"female\"])\n",
        "#df['male'] = np.where(df['sex'] == \"m\", 1, 0)\n",
        "#print(df[\"male\"])"
      ],
      "metadata": {
        "id": "SutEtS_eqfTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['sex']] \n",
        "        #Call tokenizer to transform input texts into the format BERT expects \n",
        "        self.texts = [tokenizer(text,\n",
        "                               padding='max_length', max_length = 512, truncation=True, #512 is maximum length for tokens in 1 sequence\n",
        "                                return_tensors=\"pt\") for text in df['essay0']] #pt for pytorch\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "smL3H1OkjU1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#my = Dataset(df)"
      ],
      "metadata": {
        "id": "O4dfWcMJ9rKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# my[0] #input_ids, token_typ_ids,attention_mask"
      ],
      "metadata": {
        "id": "NhRhYEjQ_gQ3",
        "outputId": "dc1cfec2-0964-49f2-eb02-94859a741030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_ids': tensor([[  101,  1164,  1143,   131,   178,  1156,  1567,  1106,  1341,  1115,\n",
              "            178,  1108,  1177,  1306,   119,   119,   119,   178,  1821,   170,\n",
              "          13628,   131,  1142,  1110,  1184,  1115,  2086,   119,   122,   119,\n",
              "            178,  1821,   170,   119,   119,   119,   178,   112,   182,  1136,\n",
              "          16155,  1104,  1277,   117,  1133,  2269,  1470, 21359,  1775,   119,\n",
              "            119,   119,   178,  1250,  1107,   170,  3340,  1105,  1301,  1106,\n",
              "           1278,   119,   119,   119, 23998,  1293,   112,   188,  1122,  1280,\n",
              "            136,  1971, 14673,  1113,  1103,  5250,  2087,   119,   119,   119,\n",
              "            178,   112,   182,  1126, 12686, 16468, 15647,  1690,  1107, 21718,\n",
              "           1179,   175,  4047, 21349,  2528,   117,  1133,   119,   119,   119,\n",
              "           1297,  1110,  1164,  1103,  1376,  1614,   119,   178,  1567,  1106,\n",
              "           2495,  9610,   119,   119,   119,  1139,  2666,   179,  9899,   119,\n",
              "            178,   112,   182,   170,  6228,  2564,  1105,   178,  1440,   175,\n",
              "           1186,   119,   119,   119, 11984,   131,   178,   112,   182,  3195,\n",
              "           1800,   117,  1177,  1228,  1103,  2319,   131,   119,   119,   119,\n",
              "            178,  1108,  1255,  1107,   192, 21097,  2316,  1394,   117,  2580,\n",
              "           1146,  1107,   178, 24611,   117,  1105,   182,   119,   119,   119,\n",
              "          21260,  1139,  4170, 21260,   178,  1198,  1427,  1106,  1103,  5952,\n",
              "           1298,  1121, 12686,  2050,  1394,   117,   189,  1775,   113,   184,\n",
              "            119,   119,   119,  1106,  7584,  1991,  1107,  2006,   131,   178,\n",
              "           1138, 16889, 25576,  6613,   119,   119,   119,  1199,  1104,  1139,\n",
              "           5095,  1614,   131,  5569,  1139,  5968,  3457,  1665,  1233,   119,\n",
              "            119,   119,   178,  6942,  1106, 21718,  1179,   175,  4047, 21349,\n",
              "           2528,  1544,   170,  1214,  2403,   119,   189,   119,   119,   119,\n",
              "            178,  2580,  1146,  1107,   170,  1353,  1411,  1107,  1103,  2286,\n",
              "          14291,  1204,  1105,  5871,   119,   119,   119,  1139,  1271,  1110,\n",
              "          11699,  1926,  1105,   178,  1686,  1107, 21718,  1179,   175,  4047,\n",
              "          21349,  2528,   119,   119,   119,   119,   178,  6613,  1106,  1341,\n",
              "           1103,  1269,  1236,   170, 10475,  1674,   170,  1830,   119,   119,\n",
              "            119,  1303,   112,   188,   170,  2423,  8406, 14940,   178,  1724,\n",
              "           1229,   119,   119,   119,  5952,  1298, 26965,  1565,  1201,  1137,\n",
              "           1177,  1208,   117,   188,  4487,  6512,   119,   119,   119, 23998,\n",
              "           1106,  1155,   117,  2810,  1155,  1110,  1218,  1105,  1240,  1515,\n",
              "            170,   119,   119,   119,  1554,   118,  1159,  2377,   117,  1554,\n",
              "            118,  1159,  1961,   119,   178,  1849,   175,   119,   119,   119,\n",
              "            178, 13054,  1120,  1292,  1614,   117,  1133,  1303,  1122,  2947,\n",
              "            119,   178,   112,   182,   170,   119,   119,   119,   178,  1427,\n",
              "           1303,  3055,  1105,  1567,  1142,  1282,   119,   178,   112,   182,\n",
              "            119,   119,   119,   178,   112,   182,  1500,   178,  1169,  1243,\n",
              "           1373,  1114,  2256,   118,   170,  5250,  7641,  1665,   119,   119,\n",
              "            119, 25550,  6904,  6904,  6904,  6904,  6904,  6904,  6904,  6904,\n",
              "            119,   119,   119,   119,   178,  4819,  2520,  1164,  1139,  1116,\n",
              "            119,   119,   119,  1106,  1297,   117,  1567,  1105, 25338,  3329,\n",
              "            178,  1176,  6866,   117,  6276,   117,  1126,   119,   119,   119,\n",
              "           1277,  1167,  1106,  5194,   117,  1133,  1142,  1110,   170,  1838,\n",
              "            119,   119,   119,   178,  1821,   119,   119,   119,   107,  4547,\n",
              "            117,   107,  1144,  1561,   170,  1207,  5095,  1937,  1104,   119,\n",
              "            119,   119,   178,  2580,  1146,  1485, 21718,  1665,  4515,  3452,\n",
              "           1186,   117,  1427,  1106,   188,  2087,  1111,   188,  8401,   119,\n",
              "            119,   119,  1207,  1303,   119,  1909,  1770,   132,   114,   178,\n",
              "           1575,   170, 13864,  1107,   170, 20433,  8419,  2158,  1517,   119,\n",
              "            119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]])}, array(1))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training, test and validation\n",
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                                         [int(.8 * len(df)), int(.9 * len(df))])\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXoSuNgCjdBP",
        "outputId": "ae95f7f3-a414-4b4e-fab3-473edd32caf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 100 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"sex\"].shape #43566 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPTeOanily4A",
        "outputId": "91e34227-1dcf-43ce-ecdf-85230b038bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"essay0\"].shape #43566"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf7B5OOPl1zs",
        "outputId": "8ae17b3a-be1f-4585-8c8d-6d6eb7d16f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800,)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BUILD MODEL\n",
        "\n",
        "from torch import nn\n",
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "WGF9F-3slsYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1) #input Word embedding vector of 768, output: 1 (male/female) QUESTION: or is output 2, because 2 labels? Do I have to change sex in 2 variables both hot encoded?\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "#TRAINING\n",
        "\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss() #Changed loss function because binary, before multiclass: CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            batch_loss = criterion(output, train_label)\n",
        "            total_loss_train += batch_loss.item()\n",
        "\n",
        "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            model.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_input, val_label in val_dataloader:\n",
        "                val_label = val_label.to(device)\n",
        "                mask = val_input['attention_mask'].to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, val_label)\n",
        "                total_loss_val += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "\n",
        "EPOCHS = 1\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "YX6bJwKwh-S2",
        "outputId": "e42d5f6a-c03e-4cb9-fa55-17bb819c419f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/400 [00:05<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-33bbde9a460c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-33bbde9a460c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mtotal_loss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([2])) must be the same as input size (torch.Size([2, 1]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#QUESTION:  Target size (torch.Size([2])) must be the same as input size (torch.Size([2, 1])) -> How to have it the same? "
      ],
      "metadata": {
        "id": "sqcHBlFeAliD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Model on Test Data"
      ],
      "metadata": {
        "id": "cdWOo4fVyStJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XII_S5aOgZhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict sex with topic probability vector from BERTTopic"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ViuSnvJHYYUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import matplotlib as plt"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5WEArkDpYYUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load processed data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AxBx9-dkYYUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#1. Target vector Y (sex)\n",
        "df_topic_sex = pd.read_csv(\"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien/data/processed/df_topic_sex.csv\")\n",
        "\n",
        "#2. Feature Vector X (topic probabilities)\n",
        "probs_topic_df = pd.read_csv(\"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien/data/processed/probs_topic_df.csv\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7aIo6K-FYYU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Profile_text  most_probable_topic  \\\n",
              "0      me: would love think kind intellectual: either...                   -1   \n",
              "1      chef: means. 1. workaholic. 2. love cook regar...                  126   \n",
              "2      i'm ashamed much, writing public text online d...                   -1   \n",
              "3                            work library go school. . .                   -1   \n",
              "4      hey how's going? currently vague profile know,...                   -1   \n",
              "...                                                  ...                  ...   \n",
              "54453  vibrant, expressive, caring optimist. love peo...                   -1   \n",
              "54454  i'm nick. never know write myself. i'm sure ha...                   -1   \n",
              "54455  hello! enjoy traveling, watching movies, hangi...                    4   \n",
              "54456  \"all world balls integrity one take either awa...                   -1   \n",
              "54457  odd little \"enemy\" status someone, makes seem ...                   -1   \n",
              "\n",
              "      Sex  GenderDummy_F  \n",
              "0       m              0  \n",
              "1       m              0  \n",
              "2       m              0  \n",
              "3       m              0  \n",
              "4       m              0  \n",
              "...    ..            ...  \n",
              "54453   f              1  \n",
              "54454   m              0  \n",
              "54455   m              0  \n",
              "54456   m              0  \n",
              "54457   m              0  \n",
              "\n",
              "[54458 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-289749ac-5275-49f5-90a0-8dd53cb99859\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Profile_text</th>\n",
              "      <th>most_probable_topic</th>\n",
              "      <th>Sex</th>\n",
              "      <th>GenderDummy_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>me: would love think kind intellectual: either...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chef: means. 1. workaholic. 2. love cook regar...</td>\n",
              "      <td>126</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm ashamed much, writing public text online d...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>work library go school. . .</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hey how's going? currently vague profile know,...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54453</th>\n",
              "      <td>vibrant, expressive, caring optimist. love peo...</td>\n",
              "      <td>-1</td>\n",
              "      <td>f</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54454</th>\n",
              "      <td>i'm nick. never know write myself. i'm sure ha...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54455</th>\n",
              "      <td>hello! enjoy traveling, watching movies, hangi...</td>\n",
              "      <td>4</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54456</th>\n",
              "      <td>\"all world balls integrity one take either awa...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54457</th>\n",
              "      <td>odd little \"enemy\" status someone, makes seem ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54458 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-289749ac-5275-49f5-90a0-8dd53cb99859')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-289749ac-5275-49f5-90a0-8dd53cb99859 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-289749ac-5275-49f5-90a0-8dd53cb99859');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "df_topic_sex"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AK0xzIzvYYU1",
        "outputId": "2b587b30-cf8a-43d5-fd42-62eefa1b0d40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Do a train/test split"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Zohmq_MPYYU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(probs_topic_df, df_topic_sex[\"GenderDummy_F\"], test_size=0.33, random_state=42) #random state to make it reproducible"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dKtW2t9gYYU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48956    1\n",
              "44255    1\n",
              "54302    1\n",
              "8892     1\n",
              "30910    1\n",
              "        ..\n",
              "44732    0\n",
              "54343    1\n",
              "38158    1\n",
              "860      0\n",
              "15795    0\n",
              "Name: GenderDummy_F, Length: 36486, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "y_train"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTQH78HBYYU4",
        "outputId": "8e647477-124f-4bc3-cd40-d7b487d1b9a0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "48956  0.006437  0.002602  0.001857  0.002368  0.017177  0.005662  0.003787   \n",
              "44255  0.015904  0.002583  0.002069  0.003215  0.004630  0.003914  0.003355   \n",
              "54302  0.000468  0.000296  0.000265  0.000411  0.000379  0.001118  0.000764   \n",
              "8892   0.002839  0.001696  0.001276  0.001463  0.005396  0.002859  0.002215   \n",
              "30910  0.002335  0.001416  0.001050  0.001219  0.004245  0.002375  0.001846   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "44732  0.001199  0.001421  0.001442  0.002190  0.001068  0.002222  0.001859   \n",
              "54343  0.002473  0.002483  0.002200  0.003310  0.002241  0.004085  0.003064   \n",
              "38158  0.002794  0.001788  0.001385  0.001576  0.004186  0.003187  0.002491   \n",
              "860    0.111355  0.002536  0.002299  0.003165  0.009195  0.006392  0.004346   \n",
              "15795  0.005543  0.003096  0.002471  0.005070  0.004166  0.006061  0.004023   \n",
              "\n",
              "              7         8         9  ...       221       222       223  \\\n",
              "48956  0.002911  0.003560  0.002875  ...  0.003777  0.009289  0.002541   \n",
              "44255  0.004172  0.001971  0.002839  ...  0.014646  0.006029  0.004037   \n",
              "54302  0.000876  0.000182  0.000621  ...  0.000442  0.000494  0.000305   \n",
              "8892   0.001690  0.013213  0.001648  ...  0.002141  0.002678  0.001651   \n",
              "30910  0.001409  0.011326  0.001357  ...  0.001797  0.002178  0.001390   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "44732  0.003232  0.000629  0.004768  ...  0.001289  0.001310  0.001214   \n",
              "54343  0.004061  0.001166  0.011586  ...  0.002399  0.003040  0.002110   \n",
              "38158  0.001842  0.013718  0.001734  ...  0.002247  0.002524  0.001766   \n",
              "860    0.004104  0.002840  0.003422  ...  0.006764  0.008418  0.003261   \n",
              "15795  0.005803  0.001821  0.007493  ...  0.004748  0.006547  0.003386   \n",
              "\n",
              "            224       225       226       227       228       229       230  \n",
              "48956  0.004394  0.003110  0.003816  0.004816  0.003605  0.002723  0.003906  \n",
              "44255  0.002470  0.006432  0.003507  0.005467  0.004518  0.003412  0.002078  \n",
              "54302  0.000229  0.000582  0.000723  0.000663  0.000308  0.000540  0.000192  \n",
              "8892   0.007751  0.001759  0.002064  0.002256  0.002172  0.001621  0.014132  \n",
              "30910  0.007189  0.001471  0.001711  0.001872  0.001824  0.001355  0.011834  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "44732  0.000742  0.001828  0.002096  0.001453  0.001090  0.002358  0.000656  \n",
              "54343  0.001336  0.002960  0.004754  0.002766  0.002149  0.003610  0.001226  \n",
              "38158  0.010930  0.001890  0.002174  0.002375  0.002191  0.001755  0.012003  \n",
              "860    0.003478  0.004901  0.003860  0.006064  0.003771  0.003192  0.002986  \n",
              "15795  0.002146  0.005613  0.005087  0.004878  0.003441  0.004584  0.001911  \n",
              "\n",
              "[36486 rows x 231 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c3ec779-20d0-46c7-8516-0647e80f9deb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48956</th>\n",
              "      <td>0.006437</td>\n",
              "      <td>0.002602</td>\n",
              "      <td>0.001857</td>\n",
              "      <td>0.002368</td>\n",
              "      <td>0.017177</td>\n",
              "      <td>0.005662</td>\n",
              "      <td>0.003787</td>\n",
              "      <td>0.002911</td>\n",
              "      <td>0.003560</td>\n",
              "      <td>0.002875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003777</td>\n",
              "      <td>0.009289</td>\n",
              "      <td>0.002541</td>\n",
              "      <td>0.004394</td>\n",
              "      <td>0.003110</td>\n",
              "      <td>0.003816</td>\n",
              "      <td>0.004816</td>\n",
              "      <td>0.003605</td>\n",
              "      <td>0.002723</td>\n",
              "      <td>0.003906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44255</th>\n",
              "      <td>0.015904</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.003215</td>\n",
              "      <td>0.004630</td>\n",
              "      <td>0.003914</td>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.004172</td>\n",
              "      <td>0.001971</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014646</td>\n",
              "      <td>0.006029</td>\n",
              "      <td>0.004037</td>\n",
              "      <td>0.002470</td>\n",
              "      <td>0.006432</td>\n",
              "      <td>0.003507</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>0.004518</td>\n",
              "      <td>0.003412</td>\n",
              "      <td>0.002078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54302</th>\n",
              "      <td>0.000468</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.000379</td>\n",
              "      <td>0.001118</td>\n",
              "      <td>0.000764</td>\n",
              "      <td>0.000876</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000621</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.000229</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8892</th>\n",
              "      <td>0.002839</td>\n",
              "      <td>0.001696</td>\n",
              "      <td>0.001276</td>\n",
              "      <td>0.001463</td>\n",
              "      <td>0.005396</td>\n",
              "      <td>0.002859</td>\n",
              "      <td>0.002215</td>\n",
              "      <td>0.001690</td>\n",
              "      <td>0.013213</td>\n",
              "      <td>0.001648</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002141</td>\n",
              "      <td>0.002678</td>\n",
              "      <td>0.001651</td>\n",
              "      <td>0.007751</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.002064</td>\n",
              "      <td>0.002256</td>\n",
              "      <td>0.002172</td>\n",
              "      <td>0.001621</td>\n",
              "      <td>0.014132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30910</th>\n",
              "      <td>0.002335</td>\n",
              "      <td>0.001416</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.001219</td>\n",
              "      <td>0.004245</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.001846</td>\n",
              "      <td>0.001409</td>\n",
              "      <td>0.011326</td>\n",
              "      <td>0.001357</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001797</td>\n",
              "      <td>0.002178</td>\n",
              "      <td>0.001390</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.001471</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.001824</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>0.011834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44732</th>\n",
              "      <td>0.001199</td>\n",
              "      <td>0.001421</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>0.002190</td>\n",
              "      <td>0.001068</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>0.001859</td>\n",
              "      <td>0.003232</td>\n",
              "      <td>0.000629</td>\n",
              "      <td>0.004768</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001289</td>\n",
              "      <td>0.001310</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>0.000742</td>\n",
              "      <td>0.001828</td>\n",
              "      <td>0.002096</td>\n",
              "      <td>0.001453</td>\n",
              "      <td>0.001090</td>\n",
              "      <td>0.002358</td>\n",
              "      <td>0.000656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54343</th>\n",
              "      <td>0.002473</td>\n",
              "      <td>0.002483</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.003310</td>\n",
              "      <td>0.002241</td>\n",
              "      <td>0.004085</td>\n",
              "      <td>0.003064</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.001166</td>\n",
              "      <td>0.011586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002399</td>\n",
              "      <td>0.003040</td>\n",
              "      <td>0.002110</td>\n",
              "      <td>0.001336</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.004754</td>\n",
              "      <td>0.002766</td>\n",
              "      <td>0.002149</td>\n",
              "      <td>0.003610</td>\n",
              "      <td>0.001226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38158</th>\n",
              "      <td>0.002794</td>\n",
              "      <td>0.001788</td>\n",
              "      <td>0.001385</td>\n",
              "      <td>0.001576</td>\n",
              "      <td>0.004186</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>0.002491</td>\n",
              "      <td>0.001842</td>\n",
              "      <td>0.013718</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002247</td>\n",
              "      <td>0.002524</td>\n",
              "      <td>0.001766</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.001890</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.002191</td>\n",
              "      <td>0.001755</td>\n",
              "      <td>0.012003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.111355</td>\n",
              "      <td>0.002536</td>\n",
              "      <td>0.002299</td>\n",
              "      <td>0.003165</td>\n",
              "      <td>0.009195</td>\n",
              "      <td>0.006392</td>\n",
              "      <td>0.004346</td>\n",
              "      <td>0.004104</td>\n",
              "      <td>0.002840</td>\n",
              "      <td>0.003422</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006764</td>\n",
              "      <td>0.008418</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.003478</td>\n",
              "      <td>0.004901</td>\n",
              "      <td>0.003860</td>\n",
              "      <td>0.006064</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.003192</td>\n",
              "      <td>0.002986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>0.005543</td>\n",
              "      <td>0.003096</td>\n",
              "      <td>0.002471</td>\n",
              "      <td>0.005070</td>\n",
              "      <td>0.004166</td>\n",
              "      <td>0.006061</td>\n",
              "      <td>0.004023</td>\n",
              "      <td>0.005803</td>\n",
              "      <td>0.001821</td>\n",
              "      <td>0.007493</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004748</td>\n",
              "      <td>0.006547</td>\n",
              "      <td>0.003386</td>\n",
              "      <td>0.002146</td>\n",
              "      <td>0.005613</td>\n",
              "      <td>0.005087</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>0.004584</td>\n",
              "      <td>0.001911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36486 rows × 231 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c3ec779-20d0-46c7-8516-0647e80f9deb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c3ec779-20d0-46c7-8516-0647e80f9deb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c3ec779-20d0-46c7-8516-0647e80f9deb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "X_train\n",
        "#we have 231 columns topics and 36486 user profile texts "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "jfOLrv1MYYU5",
        "outputId": "9e6566a0-f390-4465-9b31-da1d5f2b7908"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert X and y labels to numpy"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qih1r2wrYYU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train = X_train.to_numpy()\n",
        "y_train = y_train.to_numpy()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j0cwrzLxYYU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_test = X_test.to_numpy()\n",
        "X_test = torch.from_numpy(X_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3ctgMWXcYYU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_test = y_test.to_numpy()\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w7ygMvAOYYU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make X and y labels tensors"
      ],
      "metadata": {
        "collapsed": false,
        "id": "CBKAF1uZYYU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train = torch.from_numpy(X_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hstbhl7qYYU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([36486, 231])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlHYQUs9YYU-",
        "outputId": "464eb738-9ed4-4fd9-f7a0-e87f89a83b85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_train = torch.from_numpy(y_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7ggcv8XKYYU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "type(y_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaBjFLkLYYU_",
        "outputId": "4e4e895c-ec50-4bef-ae6a-0b793b0a1404"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([36486])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-suTPNDYYVA",
        "outputId": "cd68ba0f-e087-4d59-e831-b5e269930091"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([36486, 231]), torch.Size([36486]))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JTWxgyIYYVA",
        "outputId": "7d411fc7-cba2-466b-cc36-c8561166d7bb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0064, 0.0026, 0.0019,  ..., 0.0036, 0.0027, 0.0039],\n",
              "         [0.0159, 0.0026, 0.0021,  ..., 0.0045, 0.0034, 0.0021],\n",
              "         [0.0005, 0.0003, 0.0003,  ..., 0.0003, 0.0005, 0.0002],\n",
              "         [0.0028, 0.0017, 0.0013,  ..., 0.0022, 0.0016, 0.0141],\n",
              "         [0.0023, 0.0014, 0.0010,  ..., 0.0018, 0.0014, 0.0118]],\n",
              "        dtype=torch.float64), tensor([1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "X_train[:5], y_train[:5]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FSlAZrOYYVB",
        "outputId": "3542b06c-5a4f-42ac-fe1b-2a72029187e0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZxLB9tZRYYVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Workflow"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JsV6S8aJYYVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a model (input, output size, forward pass)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "X33VS7YFYYVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "collapsed": false,
        "id": "yRVsPB8YYYVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Make device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsbquH7ZYYVC",
        "outputId": "1e8ddf59-5d6e-444a-bbf0-35b259a06864"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1. Construct a model class that subclasses nn.Module\n",
        "class NeuralNetwork_binary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
        "        self.layer_1 = nn.Linear(in_features=231, out_features=500) # takes in 231 features (X), produces 500 features QUESTION: How many output features here (meaning how many hidden layers?)\n",
        "        self.layer_2 = nn.Linear(in_features=500, out_features=500)\n",
        "        self.layer_3 = nn.Linear(in_features=500, out_features=1) # takes in 500 features, produces 1 feature (y)\n",
        "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
        "\n",
        "    # 3. Define a forward method containing the forward pass computation\n",
        "    def forward(self, x):\n",
        "        # Return the output of layer_2, a single feature, the same shape as y\n",
        "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x))))) # computation goes through layer_1 first then the output of layer_1 goes through layer_2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Gs-TJgQvYYVD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork_binary(\n",
              "  (layer_1): Linear(in_features=231, out_features=500, bias=True)\n",
              "  (layer_2): Linear(in_features=500, out_features=500, bias=True)\n",
              "  (layer_3): Linear(in_features=500, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# 4. Create an instance of the model and send it to target device\n",
        "model_0 = NeuralNetwork_binary().to(device)\n",
        "model_0"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DGdymCkYYVE",
        "outputId": "e7cc34db-548c-4777-ed18-55528f2e3106"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.) Construct loss and optimizer\n",
        "Iterate this:\n",
        "3.) Training Loop:\n",
        "    - forward pass: compute prediction\n",
        "    - backward pass: gradients\n",
        "    - Update weights"
      ],
      "metadata": {
        "collapsed": false,
        "id": "tce1j-wgYYVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Loss Function and Optimizer\n",
        "Because we have a binary classification problem: Use binary cross entropy as loss function\n",
        "We use Stochastic Gradient Descent as optimizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c2kTbCdMYYVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create a loss function\n",
        "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "# Create an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Gds-oMBYYVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a function for calculating accuracy as evaluation metric"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9J3cWeVhYYVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "671GU0jLYYVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "1. Forward Pass: Model goes through all of the training data once\n",
        "2. Calculate the Loss\n",
        "3. Set optimizer gradients to zero\n",
        "4. Perform backpropagation on the Loss\n",
        "5. Update the parameters with gradient descent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "xLSbjL3aYYVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# Put data to target device TODO: What does that mean?\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wj9Q1Hb6YYVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.69101, Accuracy: 59.85% | Test loss: 0.68970, Test acc: 60.15%\n",
            "Epoch: 10 | Loss: 0.68218, Accuracy: 59.85% | Test loss: 0.68116, Test acc: 60.15%\n",
            "Epoch: 20 | Loss: 0.67785, Accuracy: 59.85% | Test loss: 0.67690, Test acc: 60.15%\n",
            "Epoch: 30 | Loss: 0.67570, Accuracy: 59.85% | Test loss: 0.67475, Test acc: 60.15%\n",
            "Epoch: 40 | Loss: 0.67464, Accuracy: 59.85% | Test loss: 0.67365, Test acc: 60.15%\n",
            "Epoch: 50 | Loss: 0.67412, Accuracy: 59.85% | Test loss: 0.67308, Test acc: 60.15%\n",
            "Epoch: 60 | Loss: 0.67386, Accuracy: 59.85% | Test loss: 0.67279, Test acc: 60.15%\n",
            "Epoch: 70 | Loss: 0.67373, Accuracy: 59.85% | Test loss: 0.67263, Test acc: 60.15%\n",
            "Epoch: 80 | Loss: 0.67367, Accuracy: 59.85% | Test loss: 0.67254, Test acc: 60.15%\n",
            "Epoch: 90 | Loss: 0.67364, Accuracy: 59.85% | Test loss: 0.67249, Test acc: 60.15%\n"
          ]
        }
      ],
      "source": [
        "# Build training and evaluation loop\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass (model outputs raw logits)\n",
        "    y_logits = model_0(X_train.float()).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
        "\n",
        "    # 2. Calculate loss/accuracy\n",
        "    loss = loss_fn(y_logits,\n",
        "                   y_train.float())\n",
        "    acc = accuracy_fn(y_true=y_train.float(),\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        # 1. Forward pass\n",
        "        test_logits = model_0(X_test.float()).squeeze()\n",
        "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "        # 2. Caculate loss/accuracy\n",
        "        test_loss = loss_fn(test_logits,\n",
        "                            y_test.float())\n",
        "        test_acc = accuracy_fn(y_true=y_test.float(),\n",
        "                               y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmPHZS3cYYVI",
        "outputId": "dacaa0d8-4bf3-4130-8b86-adfabc4a9d85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#QUESTION: How to improve accuracy? Parameter optimization with Grid Search? How to decide on how many layers to have? "
      ],
      "metadata": {
        "id": "quHcAdNBAbY-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Pytorch_predict_sex_with_topic_probs.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}