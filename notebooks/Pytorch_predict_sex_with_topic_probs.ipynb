{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect Notebook to Google Drive\n"
      ],
      "metadata": {
        "id": "ZmRrNGr7cfUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUnoRVJ8ZENI",
        "outputId": "19809cc4-7dfd-4d97-b15d-ee8387f21cfc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "TwJ-5q_hZxT7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "root_path = \"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU1cwyb1ZyNg",
        "outputId": "ace8c864-7f2a-4f46-b736-1fd28ac49a29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction: Get Word Embedding Vector with BERT "
      ],
      "metadata": {
        "id": "rDqercXygil-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial: https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f"
      ],
      "metadata": {
        "id": "awJuCPYwoX7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install transformers"
      ],
      "metadata": {
        "id": "Hm3bBtKFhXiD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "s8NJEHcnhR8t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in dataset\n",
        "df_raw = pd.read_csv(\"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien/data/raw/okcupid_profiles.csv\")\n",
        "df_raw.head(5)\n",
        "df = df_raw[[\"sex\", \"essay0\"]]\n"
      ],
      "metadata": {
        "id": "O7VxYnXHhkhT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMYbZkIyo7nr",
        "outputId": "58d3e244-52b4-426f-edc7-0ee4f4f5b4b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59946, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby([\"sex\"]).size().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "B8gMNj_1o_2i",
        "outputId": "b617e598-f88f-43c3-8a09-5742493a0c61"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3c631edb90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"female\"] = [\"1\" if x == \"f\" else \"0\" for x in df[\"sex\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SutEtS_eqfTQ",
        "outputId": "bfc00790-73fd-4ea9-d078-03d5fc3b51fc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT input Variables: \n",
        "* input_ids: id representation of each token (When decoded: \"[CLS] text [SEP] [PAD]...\"\n",
        "* token_typ_ids: Binary mask that identifies in which sequence a token belongs, for a single sequence all token type ids are 0\n",
        "* attention_mask: Binary mask that identifies whether a token is a real word or just padding\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0ERI0iOCpaU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "labels = {'f': 1,          \n",
        "          \"m\": 0}"
      ],
      "metadata": {
        "id": "fYHSmG_Ho2t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['sex']]\n",
        "        self.texts = [tokenizer(essay0,\n",
        "                               padding='max_length', max_length = 512, truncation=True, #512 is maximum length for tokens in 1 sequence\n",
        "                                return_tensors=\"pt\") for essay0 in df['essay0']]#.astype(str) #pt for pytorch\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "smL3H1OkjU1W"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training, test and validation\n",
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                                         [int(.8 * len(df)), int(.9 * len(df))])\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXoSuNgCjdBP",
        "outputId": "2d8b2068-c95b-4933-be4d-30c8e258ebc9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47956 5995 5995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"sex\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPTeOanily4A",
        "outputId": "e4bef70d-0fc7-4e43-d219-5c307d20fa09"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5084,)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"essay0\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf7B5OOPl1zs",
        "outputId": "a326fd33-e2f2-43a6-d484-9612ffe3f186"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5084,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BUILD MODEL\n",
        "\n",
        "from torch import nn\n",
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "WGF9F-3slsYU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1) #input Word embedding vector of 768, output: 1 (male/female)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "#TRAINING\n",
        "\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss() #Changed loss function because binary: CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            batch_loss = criterion(output, train_label)\n",
        "            total_loss_train += batch_loss.item()\n",
        "\n",
        "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            model.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_input, val_label in val_dataloader:\n",
        "                val_label = val_label.to(device)\n",
        "                mask = val_input['attention_mask'].to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, val_label)\n",
        "                total_loss_val += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n",
        "\n",
        "EPOCHS = 5\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "YX6bJwKwh-S2",
        "outputId": "0fe1debb-62f8-4539-a0ce-57d3c9ad928a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-93de3b13fedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-93de3b13fedd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-407aa3f56b5a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         self.texts = [tokenizer(essay0,\n\u001b[1;32m      7\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#512 is maximum length for tokens in 1 sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-407aa3f56b5a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         self.texts = [tokenizer(essay0,\n\u001b[1;32m      7\u001b[0m                                \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#512 is maximum length for tokens in 1 sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'm'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XII_S5aOgZhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\# Predict sex with topic probability vector from BERTTopic"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ViuSnvJHYYUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import matplotlib as plt"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5WEArkDpYYUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load processed data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AxBx9-dkYYUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#1. Target vector Y (sex)\n",
        "df_topic_sex = pd.read_csv(\"C:/Users/norap/Documents/GitHub/Machine Learning NLP TU Wien/data/processed/df_topic_sex.csv\")\n",
        "\n",
        "#2. Feature Vector X (topic probabilities)\n",
        "probs_topic_df = pd.read_csv(\"C:/Users/norap/Documents/GitHub/Machine Learning NLP TU Wien/data/processed/probs_topic_df.csv\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7aIo6K-FYYU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "                                            Profile_text  most_probable_topic  \\\n0      currently working international agent freight ...                   -1   \n1               dedicating everyday unbelievable badass.                   -1   \n2      make nerdy software musicians, artists, experi...                   -1   \n3                 reading things written old dead people                    2   \n4                             work work work work + play                  100   \n...                                                  ...                  ...   \n52369  happiest times life came ran it-not ahead it. ...                   -1   \n52370  currently finishing school film production, em...                   17   \n52371  i'm civil engineer, enjoys helping citizens sa...                    0   \n52372  following dreams... \"you got dream... gotta pr...                  114   \n52373  work elderly people (psychotherapy case manage...                  367   \n\n      Sex  GenderDummy_F  \n0       m              0  \n1       m              0  \n2       m              0  \n3       m              0  \n4       m              0  \n...    ..            ...  \n52369   f              1  \n52370   m              0  \n52371   m              0  \n52372   m              0  \n52373   m              0  \n\n[52374 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Profile_text</th>\n      <th>most_probable_topic</th>\n      <th>Sex</th>\n      <th>GenderDummy_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>currently working international agent freight ...</td>\n      <td>-1</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dedicating everyday unbelievable badass.</td>\n      <td>-1</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>make nerdy software musicians, artists, experi...</td>\n      <td>-1</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>reading things written old dead people</td>\n      <td>2</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>work work work work + play</td>\n      <td>100</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>52369</th>\n      <td>happiest times life came ran it-not ahead it. ...</td>\n      <td>-1</td>\n      <td>f</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>52370</th>\n      <td>currently finishing school film production, em...</td>\n      <td>17</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52371</th>\n      <td>i'm civil engineer, enjoys helping citizens sa...</td>\n      <td>0</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52372</th>\n      <td>following dreams... \"you got dream... gotta pr...</td>\n      <td>114</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52373</th>\n      <td>work elderly people (psychotherapy case manage...</td>\n      <td>367</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>52374 rows × 4 columns</p>\n</div>"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_topic_sex"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AK0xzIzvYYU1",
        "outputId": "bcd1a074-c1e1-4157-b944-35812cb7e66d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Do a train/test split"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Zohmq_MPYYU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(probs_topic_df, df_topic_sex[\"GenderDummy_F\"], test_size=0.33, random_state=42) #random state to make it reproducible"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dKtW2t9gYYU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "2109     0\n13196    0\n44691    1\n27049    0\n2054     0\n        ..\n11284    1\n44732    1\n38158    0\n860      0\n15795    1\nName: GenderDummy_F, Length: 35090, dtype: int64"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GTQH78HBYYU4",
        "outputId": "86acf099-7c40-48a2-9ec5-007e913d7ecb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "              0         1         2         3         4         5         6  \\\n2109   0.001206  0.001502  0.001697  0.000855  0.002416  0.001533  0.001414   \n13196  0.003484  0.154340  0.004782  0.001687  0.002139  0.005328  0.002260   \n44691  0.000043  0.000037  0.000042  0.000024  0.000043  0.000033  0.000033   \n27049  0.002351  0.001810  0.002068  0.001470  0.001427  0.002427  0.002133   \n2054   0.002414  0.003622  0.004320  0.001426  0.001689  0.005036  0.001918   \n...         ...       ...       ...       ...       ...       ...       ...   \n11284  0.000352  0.000379  0.000403  0.000271  0.000570  0.000397  0.000388   \n44732  0.002725  0.001856  0.001737  0.001121  0.001986  0.001712  0.002238   \n38158  0.000555  0.000745  0.000840  0.000368  0.001270  0.000709  0.000633   \n860    0.003198  0.043703  0.003990  0.001507  0.001753  0.004981  0.001999   \n15795  0.000205  0.000320  0.000395  0.000121  0.000276  0.000315  0.000199   \n\n              7         8         9  ...       358       359       360  \\\n2109   0.001180  0.001420  0.001109  ...  0.003383  0.001264  0.001343   \n13196  0.001843  0.002701  0.001604  ...  0.003132  0.001871  0.002225   \n44691  0.000038  0.000052  0.000031  ...  0.000041  0.000041  0.000067   \n27049  0.001666  0.001606  0.001365  ...  0.001934  0.001718  0.002072   \n2054   0.001586  0.002067  0.001336  ...  0.002494  0.001607  0.002168   \n...         ...       ...       ...  ...       ...       ...       ...   \n11284  0.000348  0.000367  0.000337  ...  0.000625  0.000368  0.000361   \n44732  0.001472  0.001639  0.001304  ...  0.003212  0.001592  0.001814   \n38158  0.000521  0.000693  0.000483  ...  0.002000  0.000561  0.000614   \n860    0.001599  0.002255  0.001385  ...  0.002540  0.001616  0.001896   \n15795  0.000175  0.000262  0.000151  ...  0.000428  0.000188  0.000199   \n\n            361       362       363       364       365       366       367  \n2109   0.001907  0.001649  0.002387  0.001809  0.001366  0.001232  0.001509  \n13196  0.003167  0.004520  0.003693  0.003384  0.003608  0.003403  0.002336  \n44691  0.000101  0.000075  0.000078  0.000054  0.000047  0.000031  0.000075  \n27049  0.001869  0.003574  0.002021  0.002159  0.001928  0.002908  0.001870  \n2054   0.002195  0.006054  0.002903  0.002494  0.002164  0.003888  0.002087  \n...         ...       ...       ...       ...       ...       ...       ...  \n11284  0.000453  0.000395  0.000488  0.000428  0.000377  0.000346  0.000409  \n44732  0.003720  0.002595  0.002875  0.004398  0.003122  0.001567  0.002133  \n38158  0.001045  0.000809  0.001394  0.000929  0.000660  0.000544  0.000750  \n860    0.002542  0.003810  0.002917  0.002835  0.003082  0.003238  0.001965  \n15795  0.000340  0.000356  0.000624  0.000379  0.000251  0.000210  0.000279  \n\n[35090 rows x 368 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>358</th>\n      <th>359</th>\n      <th>360</th>\n      <th>361</th>\n      <th>362</th>\n      <th>363</th>\n      <th>364</th>\n      <th>365</th>\n      <th>366</th>\n      <th>367</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2109</th>\n      <td>0.001206</td>\n      <td>0.001502</td>\n      <td>0.001697</td>\n      <td>0.000855</td>\n      <td>0.002416</td>\n      <td>0.001533</td>\n      <td>0.001414</td>\n      <td>0.001180</td>\n      <td>0.001420</td>\n      <td>0.001109</td>\n      <td>...</td>\n      <td>0.003383</td>\n      <td>0.001264</td>\n      <td>0.001343</td>\n      <td>0.001907</td>\n      <td>0.001649</td>\n      <td>0.002387</td>\n      <td>0.001809</td>\n      <td>0.001366</td>\n      <td>0.001232</td>\n      <td>0.001509</td>\n    </tr>\n    <tr>\n      <th>13196</th>\n      <td>0.003484</td>\n      <td>0.154340</td>\n      <td>0.004782</td>\n      <td>0.001687</td>\n      <td>0.002139</td>\n      <td>0.005328</td>\n      <td>0.002260</td>\n      <td>0.001843</td>\n      <td>0.002701</td>\n      <td>0.001604</td>\n      <td>...</td>\n      <td>0.003132</td>\n      <td>0.001871</td>\n      <td>0.002225</td>\n      <td>0.003167</td>\n      <td>0.004520</td>\n      <td>0.003693</td>\n      <td>0.003384</td>\n      <td>0.003608</td>\n      <td>0.003403</td>\n      <td>0.002336</td>\n    </tr>\n    <tr>\n      <th>44691</th>\n      <td>0.000043</td>\n      <td>0.000037</td>\n      <td>0.000042</td>\n      <td>0.000024</td>\n      <td>0.000043</td>\n      <td>0.000033</td>\n      <td>0.000033</td>\n      <td>0.000038</td>\n      <td>0.000052</td>\n      <td>0.000031</td>\n      <td>...</td>\n      <td>0.000041</td>\n      <td>0.000041</td>\n      <td>0.000067</td>\n      <td>0.000101</td>\n      <td>0.000075</td>\n      <td>0.000078</td>\n      <td>0.000054</td>\n      <td>0.000047</td>\n      <td>0.000031</td>\n      <td>0.000075</td>\n    </tr>\n    <tr>\n      <th>27049</th>\n      <td>0.002351</td>\n      <td>0.001810</td>\n      <td>0.002068</td>\n      <td>0.001470</td>\n      <td>0.001427</td>\n      <td>0.002427</td>\n      <td>0.002133</td>\n      <td>0.001666</td>\n      <td>0.001606</td>\n      <td>0.001365</td>\n      <td>...</td>\n      <td>0.001934</td>\n      <td>0.001718</td>\n      <td>0.002072</td>\n      <td>0.001869</td>\n      <td>0.003574</td>\n      <td>0.002021</td>\n      <td>0.002159</td>\n      <td>0.001928</td>\n      <td>0.002908</td>\n      <td>0.001870</td>\n    </tr>\n    <tr>\n      <th>2054</th>\n      <td>0.002414</td>\n      <td>0.003622</td>\n      <td>0.004320</td>\n      <td>0.001426</td>\n      <td>0.001689</td>\n      <td>0.005036</td>\n      <td>0.001918</td>\n      <td>0.001586</td>\n      <td>0.002067</td>\n      <td>0.001336</td>\n      <td>...</td>\n      <td>0.002494</td>\n      <td>0.001607</td>\n      <td>0.002168</td>\n      <td>0.002195</td>\n      <td>0.006054</td>\n      <td>0.002903</td>\n      <td>0.002494</td>\n      <td>0.002164</td>\n      <td>0.003888</td>\n      <td>0.002087</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11284</th>\n      <td>0.000352</td>\n      <td>0.000379</td>\n      <td>0.000403</td>\n      <td>0.000271</td>\n      <td>0.000570</td>\n      <td>0.000397</td>\n      <td>0.000388</td>\n      <td>0.000348</td>\n      <td>0.000367</td>\n      <td>0.000337</td>\n      <td>...</td>\n      <td>0.000625</td>\n      <td>0.000368</td>\n      <td>0.000361</td>\n      <td>0.000453</td>\n      <td>0.000395</td>\n      <td>0.000488</td>\n      <td>0.000428</td>\n      <td>0.000377</td>\n      <td>0.000346</td>\n      <td>0.000409</td>\n    </tr>\n    <tr>\n      <th>44732</th>\n      <td>0.002725</td>\n      <td>0.001856</td>\n      <td>0.001737</td>\n      <td>0.001121</td>\n      <td>0.001986</td>\n      <td>0.001712</td>\n      <td>0.002238</td>\n      <td>0.001472</td>\n      <td>0.001639</td>\n      <td>0.001304</td>\n      <td>...</td>\n      <td>0.003212</td>\n      <td>0.001592</td>\n      <td>0.001814</td>\n      <td>0.003720</td>\n      <td>0.002595</td>\n      <td>0.002875</td>\n      <td>0.004398</td>\n      <td>0.003122</td>\n      <td>0.001567</td>\n      <td>0.002133</td>\n    </tr>\n    <tr>\n      <th>38158</th>\n      <td>0.000555</td>\n      <td>0.000745</td>\n      <td>0.000840</td>\n      <td>0.000368</td>\n      <td>0.001270</td>\n      <td>0.000709</td>\n      <td>0.000633</td>\n      <td>0.000521</td>\n      <td>0.000693</td>\n      <td>0.000483</td>\n      <td>...</td>\n      <td>0.002000</td>\n      <td>0.000561</td>\n      <td>0.000614</td>\n      <td>0.001045</td>\n      <td>0.000809</td>\n      <td>0.001394</td>\n      <td>0.000929</td>\n      <td>0.000660</td>\n      <td>0.000544</td>\n      <td>0.000750</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>0.003198</td>\n      <td>0.043703</td>\n      <td>0.003990</td>\n      <td>0.001507</td>\n      <td>0.001753</td>\n      <td>0.004981</td>\n      <td>0.001999</td>\n      <td>0.001599</td>\n      <td>0.002255</td>\n      <td>0.001385</td>\n      <td>...</td>\n      <td>0.002540</td>\n      <td>0.001616</td>\n      <td>0.001896</td>\n      <td>0.002542</td>\n      <td>0.003810</td>\n      <td>0.002917</td>\n      <td>0.002835</td>\n      <td>0.003082</td>\n      <td>0.003238</td>\n      <td>0.001965</td>\n    </tr>\n    <tr>\n      <th>15795</th>\n      <td>0.000205</td>\n      <td>0.000320</td>\n      <td>0.000395</td>\n      <td>0.000121</td>\n      <td>0.000276</td>\n      <td>0.000315</td>\n      <td>0.000199</td>\n      <td>0.000175</td>\n      <td>0.000262</td>\n      <td>0.000151</td>\n      <td>...</td>\n      <td>0.000428</td>\n      <td>0.000188</td>\n      <td>0.000199</td>\n      <td>0.000340</td>\n      <td>0.000356</td>\n      <td>0.000624</td>\n      <td>0.000379</td>\n      <td>0.000251</td>\n      <td>0.000210</td>\n      <td>0.000279</td>\n    </tr>\n  </tbody>\n</table>\n<p>35090 rows × 368 columns</p>\n</div>"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jfOLrv1MYYU5",
        "outputId": "b57cdd58-514b-4cb9-a574-8ae24d7f386d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert X and y labels to numpy"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qih1r2wrYYU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train = X_train.to_numpy()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j0cwrzLxYYU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_train = y_train.to_numpy()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DpqZzZOzYYU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_test = X_test.to_numpy()\n",
        "X_test = torch.from_numpy(X_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3ctgMWXcYYU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_test = y_test.to_numpy()\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w7ygMvAOYYU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make X and y labels tensors"
      ],
      "metadata": {
        "collapsed": false,
        "id": "CBKAF1uZYYU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train = torch.from_numpy(X_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hstbhl7qYYU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "torch.Size([35090, 368])"
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PlHYQUs9YYU-",
        "outputId": "a9d10400-34a0-4528-d046-59a60d315c43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_train = torch.from_numpy(y_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7ggcv8XKYYU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "torch.Tensor"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(y_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vaBjFLkLYYU_",
        "outputId": "2f2fd8d7-018a-4dec-a276-3adb2d02821a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "torch.Size([35090])"
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "C-suTPNDYYVA",
        "outputId": "51e21db2-84a5-4340-b591-baf2c07c3ea9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "(torch.Size([35090, 368]), torch.Size([35090]))"
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9JTWxgyIYYVA",
        "outputId": "ba68ad40-8670-486d-a5db-d20d8ede8a27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "(tensor([[1.2063e-03, 1.5015e-03, 1.6973e-03,  ..., 1.3657e-03, 1.2316e-03,\n          1.5085e-03],\n         [3.4836e-03, 1.5434e-01, 4.7818e-03,  ..., 3.6082e-03, 3.4034e-03,\n          2.3365e-03],\n         [4.2651e-05, 3.6638e-05, 4.2236e-05,  ..., 4.7134e-05, 3.0976e-05,\n          7.4609e-05],\n         [2.3508e-03, 1.8099e-03, 2.0679e-03,  ..., 1.9282e-03, 2.9085e-03,\n          1.8704e-03],\n         [2.4140e-03, 3.6219e-03, 4.3196e-03,  ..., 2.1642e-03, 3.8883e-03,\n          2.0872e-03]], dtype=torch.float64),\n tensor([0, 0, 1, 0, 0]))"
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:5], y_train[:5]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2FSlAZrOYYVB",
        "outputId": "0a03d936-64cb-490c-8546-41d4aad45bd4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZxLB9tZRYYVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Workflow"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JsV6S8aJYYVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a model (input, output size, forward pass)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "X33VS7YFYYVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "collapsed": false,
        "id": "yRVsPB8YYYVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "'cpu'"
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KsbquH7ZYYVC",
        "outputId": "751dd724-6b34-4492-98be-4c068ac4677d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1. Construct a model class that subclasses nn.Module\n",
        "class NeuralNetwork_binary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
        "        self.layer_1 = nn.Linear(in_features=368, out_features=500) # takes in 370 features (X), produces 500 features TODO: How many output features here (meaning how many hidden layers?)\n",
        "        self.layer_2 = nn.Linear(in_features=500, out_features=500)\n",
        "        self.layer_3 = nn.Linear(in_features=500, out_features=1) # takes in 500 features, produces 1 feature (y)\n",
        "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
        "\n",
        "    # 3. Define a forward method containing the forward pass computation\n",
        "    def forward(self, x):\n",
        "        # Return the output of layer_2, a single feature, the same shape as y\n",
        "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x))))) # computation goes through layer_1 first then the output of layer_1 goes through layer_2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Gs-TJgQvYYVD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "NeuralNetwork_binary(\n  (layer_1): Linear(in_features=368, out_features=500, bias=True)\n  (layer_2): Linear(in_features=500, out_features=500, bias=True)\n  (layer_3): Linear(in_features=500, out_features=1, bias=True)\n  (relu): ReLU()\n)"
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Create an instance of the model and send it to target device\n",
        "model_0 = NeuralNetwork_binary().to(device)\n",
        "model_0"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6DGdymCkYYVE",
        "outputId": "a9edf9e7-782f-4fa2-faf0-6fbe07c63807"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.) Construct loss and optimizer\n",
        "Iterate this:\n",
        "3.) Training Loop:\n",
        "    - forward pass: compute prediction\n",
        "    - backward pass: gradients\n",
        "    - Update weights"
      ],
      "metadata": {
        "collapsed": false,
        "id": "tce1j-wgYYVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Loss Function and Optimizer\n",
        "Because we have a binary classification problem: Use binary cross entropy as loss function\n",
        "We use Stochastic Gradient Descent as optimizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c2kTbCdMYYVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create a loss function\n",
        "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "# Create an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Gds-oMBYYVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a function for calculating accuracy as evaluation metric"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9J3cWeVhYYVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "671GU0jLYYVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "1. Forward Pass: Model goes through all of the training data once\n",
        "2. Calculate the Loss\n",
        "3. Set optimizer gradients to zero\n",
        "4. Perform backpropagation on the Loss\n",
        "5. Update the parameters with gradient descent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "xLSbjL3aYYVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# Put data to target device TODO: What does that mean?\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wj9Q1Hb6YYVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 | Loss: 0.69068, Accuracy: 60.21% | Test loss: 0.68963, Test acc: 59.63%\n",
            "Epoch: 10 | Loss: 0.68130, Accuracy: 60.21% | Test loss: 0.68153, Test acc: 59.63%\n",
            "Epoch: 20 | Loss: 0.67663, Accuracy: 60.21% | Test loss: 0.67765, Test acc: 59.63%\n",
            "Epoch: 30 | Loss: 0.67434, Accuracy: 60.21% | Test loss: 0.67583, Test acc: 59.63%\n",
            "Epoch: 40 | Loss: 0.67321, Accuracy: 60.21% | Test loss: 0.67502, Test acc: 59.63%\n",
            "Epoch: 50 | Loss: 0.67266, Accuracy: 60.21% | Test loss: 0.67467, Test acc: 59.63%\n",
            "Epoch: 60 | Loss: 0.67240, Accuracy: 60.21% | Test loss: 0.67453, Test acc: 59.63%\n",
            "Epoch: 70 | Loss: 0.67227, Accuracy: 60.21% | Test loss: 0.67449, Test acc: 59.63%\n",
            "Epoch: 80 | Loss: 0.67221, Accuracy: 60.21% | Test loss: 0.67449, Test acc: 59.63%\n",
            "Epoch: 90 | Loss: 0.67218, Accuracy: 60.21% | Test loss: 0.67450, Test acc: 59.63%\n"
          ]
        }
      ],
      "source": [
        "# Build training and evaluation loop\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass (model outputs raw logits)\n",
        "    y_logits = model_0(X_train.float()).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
        "\n",
        "    # 2. Calculate loss/accuracy\n",
        "    loss = loss_fn(y_logits,\n",
        "                   y_train.float())\n",
        "    acc = accuracy_fn(y_true=y_train.float(),\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        # 1. Forward pass\n",
        "        test_logits = model_0(X_test.float()).squeeze()\n",
        "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "        # 2. Caculate loss/accuracy\n",
        "        test_loss = loss_fn(test_logits,\n",
        "                            y_test.float())\n",
        "        test_acc = accuracy_fn(y_true=y_test.float(),\n",
        "                               y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YmPHZS3cYYVI",
        "outputId": "5f0b9347-3986-4249-99c9-438339b16c37"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Pytorch_predict_sex_with_topic_probs.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}