{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect Notebook to Google Drive\n"
      ],
      "metadata": {
        "id": "ZmRrNGr7cfUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUnoRVJ8ZENI",
        "outputId": "d9317035-fc1d-4feb-fa3f-5bb2b997651f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = \"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien\""
      ],
      "metadata": {
        "id": "lU1cwyb1ZyNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict sex with topic probability vector from BERTTopic"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ViuSnvJHYYUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import matplotlib as plt"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5WEArkDpYYUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load processed data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AxBx9-dkYYUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/gdrive/MyDrive/Machine_Learning_NLP_Nora_Pauelsen_TU_Wien/data/processed/\""
      ],
      "metadata": {
        "id": "2cGenhzmrC2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#1. Target vector Y (sex) and most probable topic\n",
        "\n",
        "df_topics = pd.read_csv(path + \"df_topics.csv\")\n",
        "df_topics = df_topics.drop(\"Unnamed: 0\", 1)\n",
        "\n",
        "df_topics_100 = pd.read_csv(path + \"df_topics_100.csv\")\n",
        "df_topics_100 = df_topics_100.drop(\"Unnamed: 0\", 1)\n",
        "\n",
        "df_topics_50 = pd.read_csv(path + \"df_topics_50.csv\")\n",
        "df_topics_50 = df_topics_50.drop(\"Unnamed: 0\", 1)\n",
        "\n",
        "#2. Feature Vector X (topic probabilities)\n",
        "df_probs = pd.read_csv(path + \"df_probs.csv\")\n",
        "df_probs = df_probs.drop(\"Unnamed: 0\", 1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7aIo6K-FYYU0",
        "outputId": "ace9b0f7-f4b5-4f0d-d65b-56d00950e767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Profile_text  most_probable_topic Sex\n",
              "0  about me:  i would love to think that i was so...                   -1   m\n",
              "1  i am a chef: this is what that means. 1. i am ...                   -1   m\n",
              "2  i'm not ashamed of much, but writing public te...                    5   m\n",
              "3          i work in a library and go to school. . .                   -1   m\n",
              "4  hey how's it going? currently vague on the pro...                   -1   m"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caed87c6-2af8-4ef5-839b-862bcb4baf4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Profile_text</th>\n",
              "      <th>most_probable_topic</th>\n",
              "      <th>Sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>about me:  i would love to think that i was so...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm not ashamed of much, but writing public te...</td>\n",
              "      <td>5</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i work in a library and go to school. . .</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hey how's it going? currently vague on the pro...</td>\n",
              "      <td>-1</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caed87c6-2af8-4ef5-839b-862bcb4baf4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-caed87c6-2af8-4ef5-839b-862bcb4baf4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-caed87c6-2af8-4ef5-839b-862bcb4baf4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df_topics.head()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AK0xzIzvYYU1",
        "outputId": "bc927508-5248-48fb-a7c8-e424a024f15f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_probs"
      ],
      "metadata": {
        "id": "DWPiYD77sZs9",
        "outputId": "091ddb67-f625-4078-b03e-ce42be84e615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.003714  0.003332  0.004207  0.004285  0.028899  0.003352  0.003247   \n",
              "1      0.008174  0.002646  0.003544  0.003185  0.005678  0.003403  0.004280   \n",
              "2      0.002679  0.002559  0.003200  0.006352  0.003332  0.042416  0.002240   \n",
              "3      0.003110  0.002981  0.003531  0.001953  0.003629  0.002078  0.008896   \n",
              "4      0.002367  0.003329  0.004879  0.002862  0.002853  0.005279  0.002856   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "54453  0.002095  0.011450  0.040836  0.002320  0.003543  0.002442  0.003576   \n",
              "54454  0.000925  0.000365  0.000434  0.000421  0.000501  0.000463  0.000540   \n",
              "54455  0.014907  0.001963  0.002412  0.002414  0.004004  0.002413  0.003353   \n",
              "54456  0.001384  0.002377  0.002651  0.001511  0.004441  0.001263  0.001701   \n",
              "54457  0.000447  0.000332  0.000432  0.000532  0.001703  0.000410  0.000340   \n",
              "\n",
              "              7         8         9  ...       219       220       221  \\\n",
              "0      0.003272  0.004203  0.006259  ...  0.002279  0.003432  0.003922   \n",
              "1      0.003661  0.002411  0.003769  ...  0.003661  0.007638  0.005217   \n",
              "2      0.005888  0.002534  0.002981  ...  0.002084  0.002619  0.004843   \n",
              "3      0.002469  0.002209  0.003655  ...  0.002526  0.005787  0.002926   \n",
              "4      0.007899  0.002402  0.003368  ...  0.002029  0.003278  0.006281   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "54453  0.003640  0.003411  0.005755  ...  0.001636  0.003193  0.004437   \n",
              "54454  0.000464  0.000310  0.000406  ...  0.000798  0.000664  0.000500   \n",
              "54455  0.002458  0.001824  0.002609  ...  0.004383  0.005260  0.003087   \n",
              "54456  0.001437  0.002965  0.003796  ...  0.000960  0.001648  0.001774   \n",
              "54457  0.000385  0.000421  0.000594  ...  0.000261  0.000410  0.000506   \n",
              "\n",
              "            222       223       224       225       226       227  \\\n",
              "0      0.005268  0.008813  0.002133  0.004654  0.002327  0.010372   \n",
              "1      0.004998  0.004358  0.003140  0.004311  0.003427  0.005164   \n",
              "2      0.004646  0.002749  0.002459  0.002454  0.002191  0.005488   \n",
              "3      0.003137  0.004385  0.002240  0.010798  0.002827  0.002714   \n",
              "4      0.005321  0.002942  0.002506  0.002876  0.002282  0.003453   \n",
              "...         ...       ...       ...       ...       ...       ...   \n",
              "54453  0.005437  0.003899  0.001675  0.003883  0.001742  0.003044   \n",
              "54454  0.000489  0.000503  0.000931  0.000609  0.001565  0.000477   \n",
              "54455  0.002900  0.003206  0.002996  0.003398  0.003733  0.003324   \n",
              "54456  0.002284  0.004793  0.000899  0.002635  0.000991  0.002328   \n",
              "54457  0.000633  0.000692  0.000244  0.000442  0.000258  0.001929   \n",
              "\n",
              "       sum_probabilities  \n",
              "0               0.903629  \n",
              "1               0.927664  \n",
              "2               0.737023  \n",
              "3               0.808096  \n",
              "4               0.740662  \n",
              "...                  ...  \n",
              "54453           0.806925  \n",
              "54454           0.145183  \n",
              "54455           0.813876  \n",
              "54456           0.459264  \n",
              "54457           0.102705  \n",
              "\n",
              "[54458 rows x 229 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8631c845-2bcc-4319-95da-5907f3fd0727\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>sum_probabilities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003714</td>\n",
              "      <td>0.003332</td>\n",
              "      <td>0.004207</td>\n",
              "      <td>0.004285</td>\n",
              "      <td>0.028899</td>\n",
              "      <td>0.003352</td>\n",
              "      <td>0.003247</td>\n",
              "      <td>0.003272</td>\n",
              "      <td>0.004203</td>\n",
              "      <td>0.006259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002279</td>\n",
              "      <td>0.003432</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.005268</td>\n",
              "      <td>0.008813</td>\n",
              "      <td>0.002133</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>0.002327</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>0.903629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008174</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>0.003544</td>\n",
              "      <td>0.003185</td>\n",
              "      <td>0.005678</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>0.004280</td>\n",
              "      <td>0.003661</td>\n",
              "      <td>0.002411</td>\n",
              "      <td>0.003769</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003661</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.005217</td>\n",
              "      <td>0.004998</td>\n",
              "      <td>0.004358</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.004311</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>0.005164</td>\n",
              "      <td>0.927664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.002559</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.006352</td>\n",
              "      <td>0.003332</td>\n",
              "      <td>0.042416</td>\n",
              "      <td>0.002240</td>\n",
              "      <td>0.005888</td>\n",
              "      <td>0.002534</td>\n",
              "      <td>0.002981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002084</td>\n",
              "      <td>0.002619</td>\n",
              "      <td>0.004843</td>\n",
              "      <td>0.004646</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.002459</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>0.002191</td>\n",
              "      <td>0.005488</td>\n",
              "      <td>0.737023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003110</td>\n",
              "      <td>0.002981</td>\n",
              "      <td>0.003531</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.003629</td>\n",
              "      <td>0.002078</td>\n",
              "      <td>0.008896</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>0.002209</td>\n",
              "      <td>0.003655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.005787</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>0.004385</td>\n",
              "      <td>0.002240</td>\n",
              "      <td>0.010798</td>\n",
              "      <td>0.002827</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>0.808096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002367</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>0.004879</td>\n",
              "      <td>0.002862</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.005279</td>\n",
              "      <td>0.002856</td>\n",
              "      <td>0.007899</td>\n",
              "      <td>0.002402</td>\n",
              "      <td>0.003368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002029</td>\n",
              "      <td>0.003278</td>\n",
              "      <td>0.006281</td>\n",
              "      <td>0.005321</td>\n",
              "      <td>0.002942</td>\n",
              "      <td>0.002506</td>\n",
              "      <td>0.002876</td>\n",
              "      <td>0.002282</td>\n",
              "      <td>0.003453</td>\n",
              "      <td>0.740662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54453</th>\n",
              "      <td>0.002095</td>\n",
              "      <td>0.011450</td>\n",
              "      <td>0.040836</td>\n",
              "      <td>0.002320</td>\n",
              "      <td>0.003543</td>\n",
              "      <td>0.002442</td>\n",
              "      <td>0.003576</td>\n",
              "      <td>0.003640</td>\n",
              "      <td>0.003411</td>\n",
              "      <td>0.005755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001636</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>0.004437</td>\n",
              "      <td>0.005437</td>\n",
              "      <td>0.003899</td>\n",
              "      <td>0.001675</td>\n",
              "      <td>0.003883</td>\n",
              "      <td>0.001742</td>\n",
              "      <td>0.003044</td>\n",
              "      <td>0.806925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54454</th>\n",
              "      <td>0.000925</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000501</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000798</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.000931</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.145183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54455</th>\n",
              "      <td>0.014907</td>\n",
              "      <td>0.001963</td>\n",
              "      <td>0.002412</td>\n",
              "      <td>0.002414</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.002413</td>\n",
              "      <td>0.003353</td>\n",
              "      <td>0.002458</td>\n",
              "      <td>0.001824</td>\n",
              "      <td>0.002609</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004383</td>\n",
              "      <td>0.005260</td>\n",
              "      <td>0.003087</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.003206</td>\n",
              "      <td>0.002996</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.003733</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>0.813876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54456</th>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>0.002651</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.004441</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>0.001437</td>\n",
              "      <td>0.002965</td>\n",
              "      <td>0.003796</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000960</td>\n",
              "      <td>0.001648</td>\n",
              "      <td>0.001774</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.004793</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.002635</td>\n",
              "      <td>0.000991</td>\n",
              "      <td>0.002328</td>\n",
              "      <td>0.459264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54457</th>\n",
              "      <td>0.000447</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.001703</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000261</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.001929</td>\n",
              "      <td>0.102705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54458 rows Ã— 229 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8631c845-2bcc-4319-95da-5907f3fd0727')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8631c845-2bcc-4319-95da-5907f3fd0727 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8631c845-2bcc-4319-95da-5907f3fd0727');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_probs[\"most_probable_topic\"] = df_topics[\"most_probable_topic\"]"
      ],
      "metadata": {
        "id": "nn2HBd2Qwu0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_probs[\"female\"] = np.where(df_topics[\"Sex\"]==\"f\", 1,0)"
      ],
      "metadata": {
        "id": "aioWPh84s3Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_probs = df_probs.drop(\"sum_probabilities\", 1)"
      ],
      "metadata": {
        "id": "qnIKJ5Bqt1Mc",
        "outputId": "19994cd0-44df-4802-ec80-6d445769ef0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_probs"
      ],
      "metadata": {
        "id": "kwpn9lsUzmyK",
        "outputId": "33758d84-2d9e-425e-a6f6-700df2f4df1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.003714  0.003332  0.004207  0.004285  0.028899  0.003352  0.003247   \n",
              "1      0.008174  0.002646  0.003544  0.003185  0.005678  0.003403  0.004280   \n",
              "2      0.002679  0.002559  0.003200  0.006352  0.003332  0.042416  0.002240   \n",
              "3      0.003110  0.002981  0.003531  0.001953  0.003629  0.002078  0.008896   \n",
              "4      0.002367  0.003329  0.004879  0.002862  0.002853  0.005279  0.002856   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "54453  0.002095  0.011450  0.040836  0.002320  0.003543  0.002442  0.003576   \n",
              "54454  0.000925  0.000365  0.000434  0.000421  0.000501  0.000463  0.000540   \n",
              "54455  0.014907  0.001963  0.002412  0.002414  0.004004  0.002413  0.003353   \n",
              "54456  0.001384  0.002377  0.002651  0.001511  0.004441  0.001263  0.001701   \n",
              "54457  0.000447  0.000332  0.000432  0.000532  0.001703  0.000410  0.000340   \n",
              "\n",
              "              7         8         9  ...       220       221       222  \\\n",
              "0      0.003272  0.004203  0.006259  ...  0.003432  0.003922  0.005268   \n",
              "1      0.003661  0.002411  0.003769  ...  0.007638  0.005217  0.004998   \n",
              "2      0.005888  0.002534  0.002981  ...  0.002619  0.004843  0.004646   \n",
              "3      0.002469  0.002209  0.003655  ...  0.005787  0.002926  0.003137   \n",
              "4      0.007899  0.002402  0.003368  ...  0.003278  0.006281  0.005321   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "54453  0.003640  0.003411  0.005755  ...  0.003193  0.004437  0.005437   \n",
              "54454  0.000464  0.000310  0.000406  ...  0.000664  0.000500  0.000489   \n",
              "54455  0.002458  0.001824  0.002609  ...  0.005260  0.003087  0.002900   \n",
              "54456  0.001437  0.002965  0.003796  ...  0.001648  0.001774  0.002284   \n",
              "54457  0.000385  0.000421  0.000594  ...  0.000410  0.000506  0.000633   \n",
              "\n",
              "            223       224       225       226       227  most_probable_topic  \\\n",
              "0      0.008813  0.002133  0.004654  0.002327  0.010372                   -1   \n",
              "1      0.004358  0.003140  0.004311  0.003427  0.005164                   -1   \n",
              "2      0.002749  0.002459  0.002454  0.002191  0.005488                    5   \n",
              "3      0.004385  0.002240  0.010798  0.002827  0.002714                   -1   \n",
              "4      0.002942  0.002506  0.002876  0.002282  0.003453                   -1   \n",
              "...         ...       ...       ...       ...       ...                  ...   \n",
              "54453  0.003899  0.001675  0.003883  0.001742  0.003044                   -1   \n",
              "54454  0.000503  0.000931  0.000609  0.001565  0.000477                   -1   \n",
              "54455  0.003206  0.002996  0.003398  0.003733  0.003324                   -1   \n",
              "54456  0.004793  0.000899  0.002635  0.000991  0.002328                   -1   \n",
              "54457  0.000692  0.000244  0.000442  0.000258  0.001929                   -1   \n",
              "\n",
              "       female  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "54453       1  \n",
              "54454       0  \n",
              "54455       0  \n",
              "54456       0  \n",
              "54457       0  \n",
              "\n",
              "[54458 rows x 230 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ee4120c-af88-42d7-94d8-1eef212e889e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>most_probable_topic</th>\n",
              "      <th>female</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003714</td>\n",
              "      <td>0.003332</td>\n",
              "      <td>0.004207</td>\n",
              "      <td>0.004285</td>\n",
              "      <td>0.028899</td>\n",
              "      <td>0.003352</td>\n",
              "      <td>0.003247</td>\n",
              "      <td>0.003272</td>\n",
              "      <td>0.004203</td>\n",
              "      <td>0.006259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003432</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.005268</td>\n",
              "      <td>0.008813</td>\n",
              "      <td>0.002133</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>0.002327</td>\n",
              "      <td>0.010372</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008174</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>0.003544</td>\n",
              "      <td>0.003185</td>\n",
              "      <td>0.005678</td>\n",
              "      <td>0.003403</td>\n",
              "      <td>0.004280</td>\n",
              "      <td>0.003661</td>\n",
              "      <td>0.002411</td>\n",
              "      <td>0.003769</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.005217</td>\n",
              "      <td>0.004998</td>\n",
              "      <td>0.004358</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.004311</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>0.005164</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.002559</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.006352</td>\n",
              "      <td>0.003332</td>\n",
              "      <td>0.042416</td>\n",
              "      <td>0.002240</td>\n",
              "      <td>0.005888</td>\n",
              "      <td>0.002534</td>\n",
              "      <td>0.002981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002619</td>\n",
              "      <td>0.004843</td>\n",
              "      <td>0.004646</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.002459</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>0.002191</td>\n",
              "      <td>0.005488</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003110</td>\n",
              "      <td>0.002981</td>\n",
              "      <td>0.003531</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.003629</td>\n",
              "      <td>0.002078</td>\n",
              "      <td>0.008896</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>0.002209</td>\n",
              "      <td>0.003655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005787</td>\n",
              "      <td>0.002926</td>\n",
              "      <td>0.003137</td>\n",
              "      <td>0.004385</td>\n",
              "      <td>0.002240</td>\n",
              "      <td>0.010798</td>\n",
              "      <td>0.002827</td>\n",
              "      <td>0.002714</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002367</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>0.004879</td>\n",
              "      <td>0.002862</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.005279</td>\n",
              "      <td>0.002856</td>\n",
              "      <td>0.007899</td>\n",
              "      <td>0.002402</td>\n",
              "      <td>0.003368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003278</td>\n",
              "      <td>0.006281</td>\n",
              "      <td>0.005321</td>\n",
              "      <td>0.002942</td>\n",
              "      <td>0.002506</td>\n",
              "      <td>0.002876</td>\n",
              "      <td>0.002282</td>\n",
              "      <td>0.003453</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54453</th>\n",
              "      <td>0.002095</td>\n",
              "      <td>0.011450</td>\n",
              "      <td>0.040836</td>\n",
              "      <td>0.002320</td>\n",
              "      <td>0.003543</td>\n",
              "      <td>0.002442</td>\n",
              "      <td>0.003576</td>\n",
              "      <td>0.003640</td>\n",
              "      <td>0.003411</td>\n",
              "      <td>0.005755</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003193</td>\n",
              "      <td>0.004437</td>\n",
              "      <td>0.005437</td>\n",
              "      <td>0.003899</td>\n",
              "      <td>0.001675</td>\n",
              "      <td>0.003883</td>\n",
              "      <td>0.001742</td>\n",
              "      <td>0.003044</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54454</th>\n",
              "      <td>0.000925</td>\n",
              "      <td>0.000365</td>\n",
              "      <td>0.000434</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000501</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.000931</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54455</th>\n",
              "      <td>0.014907</td>\n",
              "      <td>0.001963</td>\n",
              "      <td>0.002412</td>\n",
              "      <td>0.002414</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.002413</td>\n",
              "      <td>0.003353</td>\n",
              "      <td>0.002458</td>\n",
              "      <td>0.001824</td>\n",
              "      <td>0.002609</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005260</td>\n",
              "      <td>0.003087</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.003206</td>\n",
              "      <td>0.002996</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.003733</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54456</th>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.002377</td>\n",
              "      <td>0.002651</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.004441</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>0.001437</td>\n",
              "      <td>0.002965</td>\n",
              "      <td>0.003796</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001648</td>\n",
              "      <td>0.001774</td>\n",
              "      <td>0.002284</td>\n",
              "      <td>0.004793</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.002635</td>\n",
              "      <td>0.000991</td>\n",
              "      <td>0.002328</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54457</th>\n",
              "      <td>0.000447</td>\n",
              "      <td>0.000332</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.001703</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000410</td>\n",
              "      <td>0.000506</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000692</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.001929</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54458 rows Ã— 230 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ee4120c-af88-42d7-94d8-1eef212e889e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ee4120c-af88-42d7-94d8-1eef212e889e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ee4120c-af88-42d7-94d8-1eef212e889e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_user = df_probs.iloc[1, :-2]"
      ],
      "metadata": {
        "id": "kEY7tmybwsvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_user"
      ],
      "metadata": {
        "id": "2Ky_Hy-Cylsn",
        "outputId": "6b77865b-ac6d-4e9e-f07d-914231f92028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.008174\n",
              "1      0.002646\n",
              "2      0.003544\n",
              "3      0.003185\n",
              "4      0.005678\n",
              "         ...   \n",
              "223    0.004358\n",
              "224    0.003140\n",
              "225    0.004311\n",
              "226    0.003427\n",
              "227    0.005164\n",
              "Name: 1, Length: 228, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_user.idxmax()"
      ],
      "metadata": {
        "id": "uE0BhfoSy1-m",
        "outputId": "a1b5af75-bcbb-4c15-d4bc-ac649f31eedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'209'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_probs.iloc[:,:-1]"
      ],
      "metadata": {
        "id": "WvXIJKmiuDLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Do a train/test split"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Zohmq_MPYYU2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_probs.iloc[:,:-1], df_probs[\"female\"], test_size=0.33, random_state=42) #random state to make it reproducible"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dKtW2t9gYYU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48956    1\n",
              "44255    1\n",
              "54302    1\n",
              "8892     1\n",
              "30910    1\n",
              "        ..\n",
              "44732    0\n",
              "54343    1\n",
              "38158    1\n",
              "860      0\n",
              "15795    0\n",
              "Name: female, Length: 36486, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "y_train"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTQH78HBYYU4",
        "outputId": "966ede69-80c2-4da0-9dc7-90257d477cc8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "48956  0.008038  0.000815  0.001005  0.001159  0.001838  0.001134  0.001234   \n",
              "44255  0.001452  0.002058  0.003487  0.001085  0.001703  0.001259  0.005320   \n",
              "54302  0.000556  0.001501  0.001444  0.000539  0.001057  0.000534  0.000996   \n",
              "8892   0.006649  0.001701  0.001967  0.002007  0.002276  0.002149  0.002568   \n",
              "30910  0.004601  0.001174  0.001372  0.001449  0.001569  0.001579  0.001726   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "44732  0.002334  0.005925  0.006016  0.003270  0.007022  0.002767  0.002869   \n",
              "54343  0.001802  0.002427  0.002764  0.002007  0.007222  0.001578  0.001935   \n",
              "38158  0.005077  0.001902  0.002175  0.002089  0.002341  0.002265  0.002796   \n",
              "860    0.002308  0.000561  0.000746  0.000623  0.000994  0.000685  0.001057   \n",
              "15795  0.002085  0.002908  0.004091  0.001550  0.002864  0.001615  0.005232   \n",
              "\n",
              "              7         8         9  ...       219       220       221  \\\n",
              "48956  0.001091  0.000809  0.001133  ...  0.001598  0.001752  0.001373   \n",
              "44255  0.001731  0.001256  0.002686  ...  0.001154  0.003244  0.002097   \n",
              "54302  0.000661  0.000869  0.001491  ...  0.000432  0.000880  0.000810   \n",
              "8892   0.002110  0.001482  0.001897  ...  0.009726  0.002707  0.002108   \n",
              "30910  0.001527  0.001045  0.001309  ...  0.006168  0.001907  0.001553   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "44732  0.003120  0.014041  0.007709  ...  0.001744  0.002889  0.003684   \n",
              "54343  0.001761  0.003016  0.003801  ...  0.001187  0.002038  0.002216   \n",
              "38158  0.002298  0.001590  0.002022  ...  0.006189  0.002853  0.002253   \n",
              "860    0.000755  0.000496  0.000759  ...  0.001014  0.002005  0.001020   \n",
              "15795  0.002131  0.001890  0.003844  ...  0.001503  0.004584  0.002788   \n",
              "\n",
              "            222       223       224       225       226       227  \\\n",
              "48956  0.001224  0.001255  0.001174  0.001249  0.001299  0.001667   \n",
              "44255  0.002326  0.001929  0.001116  0.002621  0.001214  0.001498   \n",
              "54302  0.001084  0.001946  0.000423  0.002106  0.000478  0.000747   \n",
              "8892   0.001894  0.001976  0.007315  0.002427  0.015144  0.002146   \n",
              "30910  0.001348  0.001379  0.006203  0.001675  0.010368  0.001547   \n",
              "...         ...       ...       ...       ...       ...       ...   \n",
              "44732  0.005191  0.006986  0.001737  0.004163  0.001855  0.004591   \n",
              "54343  0.002824  0.005524  0.001103  0.002951  0.001211  0.003265   \n",
              "38158  0.002014  0.002114  0.007411  0.002730  0.012937  0.002206   \n",
              "860    0.000955  0.000826  0.000773  0.000876  0.000851  0.000901   \n",
              "15795  0.003505  0.003221  0.001380  0.004022  0.001527  0.002230   \n",
              "\n",
              "       most_probable_topic  \n",
              "48956                   -1  \n",
              "44255                   -1  \n",
              "54302                   -1  \n",
              "8892                   158  \n",
              "30910                   -1  \n",
              "...                    ...  \n",
              "44732                   -1  \n",
              "54343                   -1  \n",
              "38158                   -1  \n",
              "860                     -1  \n",
              "15795                   -1  \n",
              "\n",
              "[36486 rows x 229 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24ef04b9-169a-421f-bf15-ec09fc16718e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>most_probable_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48956</th>\n",
              "      <td>0.008038</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>0.001005</td>\n",
              "      <td>0.001159</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>0.001134</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>0.001091</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.001133</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001598</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.001224</td>\n",
              "      <td>0.001255</td>\n",
              "      <td>0.001174</td>\n",
              "      <td>0.001249</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44255</th>\n",
              "      <td>0.001452</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>0.003487</td>\n",
              "      <td>0.001085</td>\n",
              "      <td>0.001703</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>0.005320</td>\n",
              "      <td>0.001731</td>\n",
              "      <td>0.001256</td>\n",
              "      <td>0.002686</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001154</td>\n",
              "      <td>0.003244</td>\n",
              "      <td>0.002097</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>0.001929</td>\n",
              "      <td>0.001116</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>0.001498</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54302</th>\n",
              "      <td>0.000556</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>0.001444</td>\n",
              "      <td>0.000539</td>\n",
              "      <td>0.001057</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>0.001491</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.000880</td>\n",
              "      <td>0.000810</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>0.001946</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.002106</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>0.000747</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8892</th>\n",
              "      <td>0.006649</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>0.002007</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.002149</td>\n",
              "      <td>0.002568</td>\n",
              "      <td>0.002110</td>\n",
              "      <td>0.001482</td>\n",
              "      <td>0.001897</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009726</td>\n",
              "      <td>0.002707</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>0.001894</td>\n",
              "      <td>0.001976</td>\n",
              "      <td>0.007315</td>\n",
              "      <td>0.002427</td>\n",
              "      <td>0.015144</td>\n",
              "      <td>0.002146</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30910</th>\n",
              "      <td>0.004601</td>\n",
              "      <td>0.001174</td>\n",
              "      <td>0.001372</td>\n",
              "      <td>0.001449</td>\n",
              "      <td>0.001569</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>0.001726</td>\n",
              "      <td>0.001527</td>\n",
              "      <td>0.001045</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006168</td>\n",
              "      <td>0.001907</td>\n",
              "      <td>0.001553</td>\n",
              "      <td>0.001348</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.006203</td>\n",
              "      <td>0.001675</td>\n",
              "      <td>0.010368</td>\n",
              "      <td>0.001547</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44732</th>\n",
              "      <td>0.002334</td>\n",
              "      <td>0.005925</td>\n",
              "      <td>0.006016</td>\n",
              "      <td>0.003270</td>\n",
              "      <td>0.007022</td>\n",
              "      <td>0.002767</td>\n",
              "      <td>0.002869</td>\n",
              "      <td>0.003120</td>\n",
              "      <td>0.014041</td>\n",
              "      <td>0.007709</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.002889</td>\n",
              "      <td>0.003684</td>\n",
              "      <td>0.005191</td>\n",
              "      <td>0.006986</td>\n",
              "      <td>0.001737</td>\n",
              "      <td>0.004163</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>0.004591</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54343</th>\n",
              "      <td>0.001802</td>\n",
              "      <td>0.002427</td>\n",
              "      <td>0.002764</td>\n",
              "      <td>0.002007</td>\n",
              "      <td>0.007222</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.001935</td>\n",
              "      <td>0.001761</td>\n",
              "      <td>0.003016</td>\n",
              "      <td>0.003801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001187</td>\n",
              "      <td>0.002038</td>\n",
              "      <td>0.002216</td>\n",
              "      <td>0.002824</td>\n",
              "      <td>0.005524</td>\n",
              "      <td>0.001103</td>\n",
              "      <td>0.002951</td>\n",
              "      <td>0.001211</td>\n",
              "      <td>0.003265</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38158</th>\n",
              "      <td>0.005077</td>\n",
              "      <td>0.001902</td>\n",
              "      <td>0.002175</td>\n",
              "      <td>0.002089</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.002796</td>\n",
              "      <td>0.002298</td>\n",
              "      <td>0.001590</td>\n",
              "      <td>0.002022</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006189</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.002253</td>\n",
              "      <td>0.002014</td>\n",
              "      <td>0.002114</td>\n",
              "      <td>0.007411</td>\n",
              "      <td>0.002730</td>\n",
              "      <td>0.012937</td>\n",
              "      <td>0.002206</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.002308</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.000746</td>\n",
              "      <td>0.000623</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.001057</td>\n",
              "      <td>0.000755</td>\n",
              "      <td>0.000496</td>\n",
              "      <td>0.000759</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.002005</td>\n",
              "      <td>0.001020</td>\n",
              "      <td>0.000955</td>\n",
              "      <td>0.000826</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>0.000876</td>\n",
              "      <td>0.000851</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>0.002085</td>\n",
              "      <td>0.002908</td>\n",
              "      <td>0.004091</td>\n",
              "      <td>0.001550</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>0.001615</td>\n",
              "      <td>0.005232</td>\n",
              "      <td>0.002131</td>\n",
              "      <td>0.001890</td>\n",
              "      <td>0.003844</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001503</td>\n",
              "      <td>0.004584</td>\n",
              "      <td>0.002788</td>\n",
              "      <td>0.003505</td>\n",
              "      <td>0.003221</td>\n",
              "      <td>0.001380</td>\n",
              "      <td>0.004022</td>\n",
              "      <td>0.001527</td>\n",
              "      <td>0.002230</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36486 rows Ã— 229 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24ef04b9-169a-421f-bf15-ec09fc16718e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24ef04b9-169a-421f-bf15-ec09fc16718e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24ef04b9-169a-421f-bf15-ec09fc16718e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "X_train\n",
        "#we have 228 columns topics and 36486 user profile texts "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "jfOLrv1MYYU5",
        "outputId": "8f003ac2-8abb-4ce0-fabb-959054943330"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert X and y labels to numpy"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qih1r2wrYYU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train = X_train.to_numpy()\n",
        "y_train = y_train.to_numpy()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j0cwrzLxYYU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_test = X_test.to_numpy()\n",
        "X_test = torch.from_numpy(X_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3ctgMWXcYYU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_test = y_test.to_numpy()\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w7ygMvAOYYU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make X and y labels tensors"
      ],
      "metadata": {
        "collapsed": false,
        "id": "CBKAF1uZYYU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "X_train = torch.from_numpy(X_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Hstbhl7qYYU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([36486, 229])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlHYQUs9YYU-",
        "outputId": "0ffe1ed4-e4cd-4829-e307-126e8f17aa72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_train = torch.from_numpy(y_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7ggcv8XKYYU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "type(y_train)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaBjFLkLYYU_",
        "outputId": "8dcb5400-ff3b-44de-bb3d-840b6209130e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([36486])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-suTPNDYYVA",
        "outputId": "317a59bb-913c-4374-f8da-541c4727e167"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([36486, 229]), torch.Size([36486]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JTWxgyIYYVA",
        "outputId": "f5860303-9ef3-4855-fb1c-ea4f9f47b5ac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 8.0377e-03,  8.1451e-04,  1.0053e-03,  ...,  1.2992e-03,\n",
              "           1.6667e-03, -1.0000e+00],\n",
              "         [ 1.4524e-03,  2.0584e-03,  3.4873e-03,  ...,  1.2140e-03,\n",
              "           1.4979e-03, -1.0000e+00],\n",
              "         [ 5.5613e-04,  1.5011e-03,  1.4440e-03,  ...,  4.7801e-04,\n",
              "           7.4718e-04, -1.0000e+00],\n",
              "         [ 6.6493e-03,  1.7014e-03,  1.9668e-03,  ...,  1.5144e-02,\n",
              "           2.1464e-03,  1.5800e+02],\n",
              "         [ 4.6006e-03,  1.1740e-03,  1.3718e-03,  ...,  1.0368e-02,\n",
              "           1.5472e-03, -1.0000e+00]], dtype=torch.float64),\n",
              " tensor([1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "X_train[:5], y_train[:5]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FSlAZrOYYVB",
        "outputId": "f97a1155-75ae-44f9-9f17-9689a9a60b41"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZxLB9tZRYYVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Workflow"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JsV6S8aJYYVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a model (input, output size, forward pass)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "X33VS7YFYYVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "collapsed": false,
        "id": "yRVsPB8YYYVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Make device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KsbquH7ZYYVC",
        "outputId": "593b153f-8a0b-49ca-92f7-420b454a5dae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1. Construct a model class that subclasses nn.Module\n",
        "class NeuralNetwork_binary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
        "        self.layer_1 = nn.Linear(in_features=229, out_features=500) # takes in 231 features (X), produces 500 features QUESTION: How many output features here (meaning how many hidden layers?)\n",
        "        self.layer_2 = nn.Linear(in_features=500, out_features=1)\n",
        "        #self.layer_3 = nn.Linear(in_features=500, out_features=1) # takes in 500 features, produces 1 feature (y)\n",
        "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
        "\n",
        "    # 3. Define a forward method containing the forward pass computation\n",
        "    def forward(self, x):\n",
        "        # Return the output of layer_2, a single feature, the same shape as y\n",
        "        return self.relu(self.layer_2(self.relu(self.layer_1(x)))) # computation goes through layer_1 first then the output of layer_1 goes through layer_2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Gs-TJgQvYYVD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork_binary(\n",
              "  (layer_1): Linear(in_features=229, out_features=500, bias=True)\n",
              "  (layer_2): Linear(in_features=500, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# 4. Create an instance of the model and send it to target device\n",
        "model_0 = NeuralNetwork_binary().to(device)\n",
        "model_0"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DGdymCkYYVE",
        "outputId": "9a0881ca-1896-4f39-dd50-d6d21dc2f149"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.) Construct loss and optimizer\n",
        "Iterate this:\n",
        "3.) Training Loop:\n",
        "    - forward pass: compute prediction\n",
        "    - backward pass: gradients\n",
        "    - Update weights"
      ],
      "metadata": {
        "collapsed": false,
        "id": "tce1j-wgYYVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a Loss Function and Optimizer\n",
        "Because we have a binary classification problem: Use binary cross entropy as loss function\n",
        "We use Stochastic Gradient Descent as optimizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c2kTbCdMYYVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Create a loss function\n",
        "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "# Create an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Gds-oMBYYVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a function for calculating accuracy as evaluation metric"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9J3cWeVhYYVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "671GU0jLYYVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model\n",
        "1. Forward Pass: Model goes through all of the training data once\n",
        "2. Calculate the Loss\n",
        "3. Set optimizer gradients to zero\n",
        "4. Perform backpropagation on the Loss\n",
        "5. Update the parameters with gradient descent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "xLSbjL3aYYVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 200\n",
        "#Put data to target device (Cuda if possible)\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wj9Q1Hb6YYVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BUZxy05RwGZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|â–         | 8/200 [00:00<00:02, 72.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.69436, Accuracy: 44.96% | Test loss: 0.69318, Test acc: 46.74%\n",
            "Epoch: 10 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|â–ˆâ–Š        | 37/200 [00:00<00:01, 90.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 30 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|â–ˆâ–ˆâ–Š       | 57/200 [00:00<00:01, 94.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 50 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [00:00<00:01, 96.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 70 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [00:01<00:01, 97.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 90 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [00:01<00:00, 96.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 110 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [00:01<00:00, 96.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 120 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 130 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [00:01<00:00, 96.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 140 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 150 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [00:01<00:00, 96.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 160 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 170 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 94.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 180 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n",
            "Epoch: 190 | Loss: 0.69315, Accuracy: 59.85% | Test loss: 0.69315, Test acc: 60.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Build training and evaluation loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    ### Training\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass (model outputs raw logits)\n",
        "    y_logits = model_0(X_train.float()).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
        "\n",
        "    # 2. Calculate loss/accuracy\n",
        "    loss = loss_fn(y_logits,\n",
        "                   y_train.float())\n",
        "    acc = accuracy_fn(y_true=y_train.float(),\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        # 1. Forward pass\n",
        "        test_logits = model_0(X_test.float()).squeeze()\n",
        "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "        # 2. Caculate loss/accuracy\n",
        "        test_loss = loss_fn(test_logits,\n",
        "                            y_test.float())\n",
        "        test_acc = accuracy_fn(y_true=y_test.float(),\n",
        "                               y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmPHZS3cYYVI",
        "outputId": "2321433e-6b06-44d2-9233-0cf6ada605df"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Pytorch_predict_sex_with_topic_probs.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}